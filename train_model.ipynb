{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "+----+-------+--------------+-------------------+\n",
      "|year|country|article_amount|subject_area_abbrev|\n",
      "+----+-------+--------------+-------------------+\n",
      "|2023|  Spain|          68.0|               ECON|\n",
      "|2023|  Spain|          68.0|               ECON|\n",
      "|2023|  India|         190.0|               VETE|\n",
      "|2023|  India|         190.0|               VETE|\n",
      "|2023|  India|         190.0|               VETE|\n",
      "+----+-------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test\n",
      "+----+-------+--------------+-------------------+\n",
      "|year|country|article_amount|subject_area_abbrev|\n",
      "+----+-------+--------------+-------------------+\n",
      "|2024|   Iran|          50.0|               AGRI|\n",
      "|2024|   Iran|          50.0|               AGRI|\n",
      "|2024|   Iran|          50.0|               AGRI|\n",
      "|2024|   Iran|          50.0|               AGRI|\n",
      "|2024|   Iran|          50.0|               AGRI|\n",
      "+----+-------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize SparkSession\n",
    "# spark.stop()    \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read CSV Example\") \\\n",
    "    .config(\"spark.driver.host\", \"localhost\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Step 2: Read CSV File\n",
    "file_path_train = \"./combined_data_2018_2023.csv\"  # Replace with your file path\n",
    "file_path_test = \"./final_data_prep_2024.csv\"  # Replace with your file path\n",
    "df_train = spark.read.csv(file_path_train, header=True, inferSchema=True)\n",
    "df_test = spark.read.csv(file_path_test, header=True, inferSchema=True)\n",
    "\n",
    "print(\"Train\")\n",
    "df_train.show(5)\n",
    "\n",
    "print(\"Test\")\n",
    "df_test.show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-2023 : \n",
      "Unique values in column 'year': 6\n",
      "Unique values in column 'country': 175\n",
      "Unique values in column 'article_amount': 467\n",
      "Unique values in column 'subject_area_abbrev': 27\n"
     ]
    }
   ],
   "source": [
    "print(\"2018-2023 : \")\n",
    "for column in df_train.columns:\n",
    "    unique_count = df_train.select(column).distinct().count()\n",
    "    print(f\"Unique values in column '{column}': {unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 :\n",
      "Unique values in column 'year': 1\n",
      "Unique values in column 'country': 18\n",
      "Unique values in column 'article_amount': 83\n",
      "Unique values in column 'subject_area_abbrev': 27\n"
     ]
    }
   ],
   "source": [
    "print(\"2024 :\")\n",
    "for column in df_test.columns:\n",
    "    unique_count = df_test.select(column).distinct().count()\n",
    "    print(f\"Unique values in column '{column}': {unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Schema:\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- article_amount: double (nullable = true)\n",
      " |-- subject_area_abbrev: string (nullable = true)\n",
      "\n",
      "Testing Data Schema:\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- article_amount: double (nullable = true)\n",
      " |-- subject_area_abbrev: string (nullable = true)\n",
      "\n",
      "+---------+--------------+-------------------+------------------+---------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|country  |article_amount|subject_area_abbrev|features          |country_indexed|prediction|probability                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "+---------+--------------+-------------------+------------------+---------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "|australia|69.0          |SOCI               |[2024.0,69.0,24.0]|11.0           |4.0       |[0.030307213311180654,0.058790620033805044,0.0882757630424785,0.10156755152725114,0.1084094514514015,0.026370319165082878,0.07564397431692964,0.024872587676137682,0.08513170681976515,0.047112917389892865,0.05612476773305906,0.06317125963802414,0.05007916982550796,0.05219162698176748,0.04848702647760773,0.03427222730687127,0.032997123529997896,0.016194693773239434]|\n",
      "+---------+--------------+-------------------+------------------+---------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Model Accuracy: 0.70\n",
      "Model F1 Score: 0.70\n",
      "Weightedprecision: 0.76\n",
      "Weightedrecall: 0.70\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"DataSciencePipeline\").getOrCreate()\n",
    "\n",
    "try:\n",
    "    # Read training and testing datasets without dropping duplicates\n",
    "    df_train = spark.read.csv(file_path_train, header=True, inferSchema=True)\n",
    "    # df_train = df_train.dropDuplicates()\n",
    "    df_test = spark.read.csv(file_path_test, header=True, inferSchema=True)\n",
    "    # df_test = df_test.dropDuplicates()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    spark.stop()\n",
    "    raise\n",
    "\n",
    "# Print schemas to confirm structure\n",
    "print(\"Training Data Schema:\")\n",
    "df_train.printSchema()\n",
    "print(\"Testing Data Schema:\")\n",
    "df_test.printSchema()\n",
    "\n",
    "# Ensure critical columns are present\n",
    "required_columns = [\"year\", \"article_amount\", \"subject_area_abbrev\", \"country\"]\n",
    "missing_columns_train = [col for col in required_columns if col not in df_train.columns]\n",
    "missing_columns_test = [col for col in required_columns if col not in df_test.columns]\n",
    "\n",
    "if missing_columns_train or missing_columns_test:\n",
    "    raise ValueError(f\"Missing required columns. Train: {missing_columns_train}, Test: {missing_columns_test}\")\n",
    "\n",
    "# Handle missing values\n",
    "df_train = df_train.dropna(subset=required_columns)\n",
    "df_test = df_test.dropna(subset=required_columns)\n",
    "\n",
    "# Normalize country column to avoid mismatches\n",
    "from pyspark.sql import functions as F\n",
    "df_train = df_train.withColumn(\"country\", F.trim(F.lower(F.col(\"country\"))))\n",
    "df_test = df_test.withColumn(\"country\", F.trim(F.lower(F.col(\"country\"))))\n",
    "\n",
    "# Filter datasets to have only common countries between train and test\n",
    "common_countries = df_train.select(\"country\").distinct().intersect(df_test.select(\"country\").distinct())\n",
    "df_train = df_train.join(common_countries, on=\"country\", how=\"inner\")\n",
    "df_test = df_test.join(common_countries, on=\"country\", how=\"inner\")\n",
    "\n",
    "# Handle categorical features\n",
    "subject_area_indexer = StringIndexer(inputCol=\"subject_area_abbrev\", outputCol=\"subject_area_indexed\", handleInvalid=\"skip\")\n",
    "country_indexer = StringIndexer(inputCol=\"country\", outputCol=\"country_indexed\", handleInvalid=\"skip\")\n",
    "\n",
    "# Assemble feature columns\n",
    "feature_columns = [\"year\", \"article_amount\", \"subject_area_indexed\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# RandomForestClassifier setup\n",
    "rf = RandomForestClassifier(labelCol=\"country_indexed\", featuresCol=\"features\", probabilityCol=\"probability\")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[subject_area_indexer, country_indexer, assembler, rf])\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(df_train)\n",
    "\n",
    "# Make predictions\n",
    "df_test_predictions = model.transform(df_test)\n",
    "\n",
    "# Display predictions\n",
    "df_test_predictions.select(\n",
    "    \"country\", \"article_amount\", \"subject_area_abbrev\", \"features\",\n",
    "    \"country_indexed\", \"prediction\", \"probability\"\n",
    ").show(truncate=False)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"country_indexed\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy = evaluator.evaluate(df_test_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "f1_score = evaluator.evaluate(df_test_predictions, {evaluator.metricName: \"f1\"})\n",
    "print(f\"Model F1 Score: {f1_score:.2f}\")\n",
    "\n",
    "# Evaluate precision and recall\n",
    "for metric in [\"weightedPrecision\", \"weightedRecall\"]:\n",
    "    score = evaluator.evaluate(df_test_predictions, {evaluator.metricName: metric})\n",
    "    print(f\"{metric.capitalize()}: {score:.2f}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
