{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "+----+-------+--------------+-------------------+\n",
      "|year|country|article_amount|subject_area_abbrev|\n",
      "+----+-------+--------------+-------------------+\n",
      "|2023|  Spain|          68.0|               ECON|\n",
      "|2023|  Spain|          68.0|               ECON|\n",
      "|2023|  India|         190.0|               VETE|\n",
      "|2023|  India|         190.0|               VETE|\n",
      "|2023|  India|         190.0|               VETE|\n",
      "+----+-------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test\n",
      "+----+-------+--------------+-------------------+\n",
      "|year|country|article_amount|subject_area_abbrev|\n",
      "+----+-------+--------------+-------------------+\n",
      "|2024|   Iran|          50.0|               AGRI|\n",
      "|2024|   Iran|          50.0|               AGRI|\n",
      "|2024|   Iran|          50.0|               AGRI|\n",
      "|2024|   Iran|          50.0|               AGRI|\n",
      "|2024|   Iran|          50.0|               AGRI|\n",
      "+----+-------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read CSV Example\") \\\n",
    "    .config(\"spark.driver.host\", \"localhost\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "file_path_train = \"./csv_file/combined_data_2018_2023.csv\"  \n",
    "file_path_test = \"./csv_file/final_data_prep_2024.csv\"  \n",
    "df_train = spark.read.csv(file_path_train, header=True, inferSchema=True)\n",
    "df_test = spark.read.csv(file_path_test, header=True, inferSchema=True)\n",
    "\n",
    "print(\"Train\")\n",
    "df_train.show(5)\n",
    "\n",
    "print(\"Test\")\n",
    "df_test.show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Schema:\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- article_amount: double (nullable = true)\n",
      " |-- subject_area_abbrev: string (nullable = true)\n",
      "\n",
      "Testing Data Schema:\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- article_amount: double (nullable = true)\n",
      " |-- subject_area_abbrev: string (nullable = true)\n",
      "\n",
      "Predictions have been exported to predictions_output.csv.\n",
      "Metrics have been exported to metrics_output.csv.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DataSciencePipeline\").getOrCreate()\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    df_train = spark.read.csv(file_path_train, header=True, inferSchema=True)\n",
    "    df_test = spark.read.csv(file_path_test, header=True, inferSchema=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    spark.stop()\n",
    "    raise\n",
    "\n",
    "\n",
    "print(\"Training Data Schema:\")\n",
    "df_train.printSchema()\n",
    "print(\"Testing Data Schema:\")\n",
    "df_test.printSchema()\n",
    "\n",
    "\n",
    "required_columns = [\"year\", \"article_amount\", \"subject_area_abbrev\", \"country\"]\n",
    "missing_columns_train = [col for col in required_columns if col not in df_train.columns]\n",
    "missing_columns_test = [col for col in required_columns if col not in df_test.columns]\n",
    "\n",
    "\n",
    "if missing_columns_train or missing_columns_test:\n",
    "    raise ValueError(f\"Missing required columns. Train: {missing_columns_train}, Test: {missing_columns_test}\")\n",
    "\n",
    "\n",
    "df_train = df_train.dropna(subset=required_columns)\n",
    "df_test = df_test.dropna(subset=required_columns)\n",
    "\n",
    "\n",
    "df_train = df_train.withColumn(\"country\", F.trim(F.lower(F.col(\"country\"))))\n",
    "df_test = df_test.withColumn(\"country\", F.trim(F.lower(F.col(\"country\"))))\n",
    "\n",
    "\n",
    "common_countries = df_train.select(\"country\").distinct().intersect(df_test.select(\"country\").distinct())\n",
    "df_train = df_train.join(common_countries, on=\"country\", how=\"inner\")\n",
    "df_test = df_test.join(common_countries, on=\"country\", how=\"inner\")\n",
    "\n",
    "\n",
    "subject_area_indexer = StringIndexer(inputCol=\"subject_area_abbrev\", outputCol=\"subject_area_indexed\", handleInvalid=\"skip\")\n",
    "country_indexer = StringIndexer(inputCol=\"country\", outputCol=\"country_indexed\", handleInvalid=\"skip\")\n",
    "\n",
    "\n",
    "feature_columns = [\"year\", \"article_amount\", \"subject_area_indexed\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"country_indexed\", featuresCol=\"features\", probabilityCol=\"probability\")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[subject_area_indexer, country_indexer, assembler, rf])\n",
    "\n",
    "\n",
    "model = pipeline.fit(df_train)\n",
    "\n",
    "\n",
    "df_test_predictions = model.transform(df_test)\n",
    "\n",
    "\n",
    "df_test_predictions = df_test_predictions.select(\n",
    "    \"country\", \"article_amount\", \"subject_area_abbrev\", \"features\",\n",
    "    \"country_indexed\", \"prediction\", \"probability\"\n",
    ")\n",
    "\n",
    "\n",
    "df_test_predictions_pd = df_test_predictions.toPandas()\n",
    "\n",
    "\n",
    "predictions_output_path = \"predictions_output.csv\"\n",
    "df_test_predictions_pd.to_csv(predictions_output_path, index=False)\n",
    "\n",
    "print(f\"Predictions have been exported to {predictions_output_path}.\")\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"country_indexed\", predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "accuracy = evaluator.evaluate(df_test_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "f1_score = evaluator.evaluate(df_test_predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    {\"metric\": \"accuracy\", \"value\": accuracy},\n",
    "    {\"metric\": \"f1_score\", \"value\": f1_score},\n",
    "]\n",
    "\n",
    "\n",
    "for metric in [\"weightedPrecision\", \"weightedRecall\"]:\n",
    "    score = evaluator.evaluate(df_test_predictions, {evaluator.metricName: metric})\n",
    "    metrics.append({\"metric\": metric, \"value\": score})\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "\n",
    "metrics_output_path = \"metrics_output.csv\"\n",
    "metrics_df.to_csv(metrics_output_path, index=False)\n",
    "\n",
    "print(f\"Metrics have been exported to {metrics_output_path}.\")\n",
    "\n",
    "\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
